{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm import tqdm \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ddi - Mini-Challenge zu LE3, NoSQL\n",
    "Roman Studer, Simon Luder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case\n",
    "<p align=\"center\">\n",
    "  <img src=\"./data/images/Konzept.png\" alt=\"drawing\" width=\"900\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir unterbreiten den Vorschlag eine NoSQL Datenbank (MongoDB) als Data Lake für die Speicherung von Time Series Daten zu verwenden und die Analyse besagter Daten auf einer Time-Series Datenbank durchzuführen. Die Analyse dieser Daten kann mittels einer auf Time Series optimierte Datenbank auf Abruf geschehen. Als Beispiel verwenden wir als Datenquelle openSenseMap, welche Messwerte und Sensormetainformationen über eine API zur Verfügung stellt. Ein aktiver Sensor sendet periodisch (je nach Sensor alle paar Sekunden oder Minuten) einen Messwert. Bei einem Intervall von 10 Sekunden sendet ein Sensor pro Jahr 3'153'600 Datenpunkte. \n",
    "\n",
    "OpenSenseMap erlaubt es ein ganzes Gebiet (Mittels Angabe von Breiten- und Längengrad) zu überwachen. Die Anzahl Sensoren, sowie deren Attribute kann sich über die Zeit ändern. Wenn zum Beispiel ein neuer Sensor im gleichen Gebiet in Betrieb genommen wird. Daher ist die Datenspeicherung in einer NoSQL, schemenlosen Datenbank geeignet. MongoDB ist dabei aufgrund des flexigblem Schema und einfacher horizontaler Skalierung gut geeignet. Dadurch sind wir auf Änderungen in den durch die API erhaltenen Attributen, sowie auf grosse Änderungen in der Datenmenge gewappnet. MongoDB ist allerdins nicht für die Analyse von Time Series geeignet. InfluxDB, eine Time Series Datenbank, ist für Time Series Daten optimiert und kann schnell Aggregationen über eine grosse Anzahl von Datenpunkten (über Timestamp Indexiert) durchführen. Ein Beispiel wäre ein Moving Average mit kleinem Fenster über mehrere Millionen Datenpunkte.\n",
    "\n",
    "Weiter existiert ein MongoDB-Plugin auf Telegraf welche die Performance der MongoDB überwachen kann. Somit kann das Monitoring über Influx betrieben werden. \n",
    "\n",
    "Im Anschluss setzen wir sowohl eine MongoDB als auch eine InfluxDB auf. Über ein Script laden wir alle Sensordaten auf dem Gelände der ETH-Zürich, welche OpenSenseMap zur Verfügung stellt herunter und speichern diese in der MongoDB. Im Anschluss messen wir die Zeit für Aggregationen bei steigenden Datenpunkten einzeln für beide Datenbanken, sowie für den Fall wenn MongoDB als Datalake verwendet wird. Dadurch können wir einen Punkt identifizieren ab dem es nicht mehr sinnvoll ist nur mit einer MongoDB zu arbeiten, sondern die InfluxDB zur Analyse hinzuzuziehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vergleich MongoDB vs. InfluxDB\n",
    "\n",
    "Einen Einblick in die beiden Datenbanken zu erhalten, erlaubt dass Dokument [1] \"Benchmarking InfluxDB vs. MonoDB for Time Series Data, Metrics % Management\" (siehe Anhang),\n",
    "\n",
    "| Bereich  | InfluxDB  |MongoDB  | \n",
    "|---|---|---|\n",
    "| **Verwendung** | Time-Series Datenbank | Dokumentenbasierte Datenbank, NoSQL Datenbank | \n",
    "| **Memory-Auslastung**  | ca 2-4 GB pro <100'000 Einträge [2]  | ca. 1 GB pro 100'000 Einträge [3] |\n",
    "| **Festplattenauslastung über 24h** [1]  | 178 MB |  34820 MB  |\n",
    "| **Abfragegeschwindigkeit** (Queries per Second, 1000 Einträge) [1] |  935 | 164  |\n",
    "| **Einfügegeschwindigkeit** (Werte pro Sekunde) [1] | 2,800,990  | 1,114,616  |\n",
    "| **Skalierbarkeit**  | Horizontal Skalierbar (Clustering) bei InfluxDB Enterprise [4] | Horizontal Skalierbar  |\n",
    "| **Sicherheit**  |   |   |\n",
    "| **Sprache**[1]  | C/C++  | Go |\n",
    "| **Schema**[1]  | Schemaless   | Schemaless |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenmodell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of ifu boxes at eth\n",
    "url = 'https://api.opensensemap.org/boxes?'\n",
    "bbox = '8.50269672304309, 47.40598032642525,  8.512126181507432, 47.4113301084323 ' # boundary box around eth zurich\n",
    "boxes = requests.get(url, params={'bbox':bbox, 'full':'false'}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 82/82 [04:24<00:00,  3.22s/it]\n"
     ]
    }
   ],
   "source": [
    "from_date = '2021-04-25T10:05:49.581Z'\n",
    "to_date = '2021-05-02T10:05:49.581Z'\n",
    "data_format = 'csv'\n",
    "\n",
    "for box in tqdm(boxes):\n",
    "    box_id = box['_id']\n",
    "    box_name = box['name']\n",
    "    location = box['currentLocation']['coordinates']\n",
    "    lat, lon = location[0], location[1]\n",
    "    for sensor in box['sensors']:\n",
    "        try:\n",
    "            sensor_id = sensor['_id']\n",
    "            sensor_name = sensor['title']\n",
    "            sensor_name.replace('/', '')\n",
    "            sensor_unit = sensor['unit']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #url = f'https://api.opensensemap.org/boxes/{box_id}/data/{sensor_id}?format={data_format}&download=true'\n",
    "        url = f'https://api.opensensemap.org/boxes/{box_id}/data/{sensor_id}?from-date={from_date}&to-date={to_date}&download=true&format={data_format}'\n",
    "        r = requests.get(url, stream=True)\n",
    "        if (len(r.text) > 16): # check if sensor returns values (header has length 16)\n",
    "            with open(f'./data/{box_name}_{sensor_name}.csv', 'wb') as f:\n",
    "                for _, line in enumerate(r.iter_lines()):\n",
    "                    if _ == 0: # define header\n",
    "                        line = 'box_name,sensor_name,box_id,sensor_id,lat,lon,unit,current_time,value\\n'\n",
    "                    else:\n",
    "                        time, value = (line.decode(\"utf-8\").split(','))\n",
    "                        time = time.replace('T', ' ').replace('Z', '')\n",
    "                        time = datetime.strptime(time, '%Y-%m-%d %H:%M:%S.%f').strftime('%Y-%m-%d %H:%M:%S')\n",
    "                        line= f'{box_name},{sensor_name},{box_id},{sensor_id},{lat},{lon},{sensor_unit},{time},{value}\\n'\n",
    "                    f.write(line.encode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymongo\n",
    "from pymongo import MongoClient\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_dict(path, file):\n",
    "    '''converts a csv file to a dictionary'''\n",
    "    data = pd.read_csv(path + file)\n",
    "    pd.to_datetime(data.current_time, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    dictionary = dict()\n",
    "    dictionary[\"_id\"] = file.replace('.csv', '')\n",
    "    dictionary[\"box_name\"] = data[\"box_name\"][0]\n",
    "    dictionary[\"sensor_name\"] = data[\"sensor_name\"][0]\n",
    "    dictionary[\"box_id\"] = data[\"box_id\"][0]\n",
    "    dictionary[\"sensor_id\"] = data[\"sensor_id\"][0]\n",
    "    dictionary[\"lat\"] = data[\"lat\"][0]\n",
    "    dictionary[\"lon\"] = data[\"lon\"][0]\n",
    "    dictionary[\"unit\"] = data[\"unit\"][0]\n",
    "    dictionary[\"measurments\"] = dict(zip(data[\"current_time\"], data[\"value\"]))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client = pymongo.MongoClient('localhost', 27017)\n",
    "mongo_db = mongo_client[\"ddi_mc2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 161/161 [00:04<00:00, 34.59it/s]\n"
     ]
    }
   ],
   "source": [
    "VERBOSE = False\n",
    "path = './data/'\n",
    "for file in tqdm(os.listdir(\"./data\")):\n",
    "#     print(file.split(\"_\")[0])\n",
    "    if file.endswith('.csv'): # check for filetype\n",
    "        if not mongo_db[file.split(\"_\")[0]].count_documents({\"_id\":file.replace('.csv', '')}) > 0:\n",
    "            dictionary = csv_to_dict(path, file)\n",
    "            mongo_db[file.split(\"_\")[0]].insert_one(dictionary)\n",
    "            if VERBOSE:\n",
    "                print(\"populate:\", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IFU Sensebox2021 2A',\n",
       " 'ifU SenseBox2021 10A',\n",
       " 'IfU SenseBox2021 04 A',\n",
       " 'IfU SenseBox2021 04 B',\n",
       " 'IfU SenseBox2021 5B',\n",
       " 'IfU SenseBox2021 11A',\n",
       " 'IKG Particulate Matter',\n",
       " 'IfU SenseBox2021 5A',\n",
       " 'IfU SenseBox2021 9A',\n",
       " 'IfU SenseBox 7A',\n",
       " 'IfU SenseBox2021 12',\n",
       " 'IfU SenseBox2021 2B',\n",
       " 'IfU SenseBox2021 8B',\n",
       " 'IfU SenseBox2021 3A',\n",
       " 'IfU SenseBox2021 dab',\n",
       " 'IfU SenseBox2021 1A']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo_db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IfU SenseBox2021 11A_11A Dexolved Oxygen AtlasScientific',\n",
       " 'IfU SenseBox2021 11A_11A Humidity BME680',\n",
       " 'IfU SenseBox2021 11A_11A Humidity SHT31 flex',\n",
       " 'IfU SenseBox2021 11A_11A Pressure BME680',\n",
       " 'IfU SenseBox2021 11A_11A Temperature BME680',\n",
       " 'IfU SenseBox2021 11A_11A Temperature PT1000',\n",
       " 'IfU SenseBox2021 11A_11A Temperature SHT31 flex',\n",
       " 'IfU SenseBox2021 11A_11A pH AtlasScientific']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo_db[\"IfU SenseBox2021 11A\"].find().distinct('_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup InfluxDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install influxdb-client\n",
    "from datetime import datetime\n",
    "\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "# You can generate a Token from the \"Tokens Tab\" in the UI\n",
    "token = \"uZei_UmVg7IGcllVQdvKbmbCjwx5s0pe7KfTafVspsL0qGWIg6fmB34JNwWmsEGdt9aFr2Qio6ltOB9_ZrCDDw==\"\n",
    "org = \"ddi\"\n",
    "bucket = \"ddi\"\n",
    "\n",
    "client = InfluxDBClient(url=\"http://localhost:8086\", token=token)\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "\n",
    "# RS: uZei_UmVg7IGcllVQdvKbmbCjwx5s0pe7KfTafVspsL0qGWIg6fmB34JNwWmsEGdt9aFr2Qio6ltOB9_ZrCDDw==\n",
    "# SL: AW-zLqzOTpQW4sRYaKbdXpSxBLkxT8rT-RZA-IS5MYo41RZ40YoOCoNYTyu9S2La5W4KpcDzDgCfj53fk6aZuw=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checks': [],\n",
       " 'commit': '4db98b4c9a',\n",
       " 'message': 'ready for queries and writes',\n",
       " 'name': 'influxdb',\n",
       " 'status': 'pass',\n",
       " 'version': '2.0.6'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.health()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query MongoDB, insert into InfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IFU Sensebox2021 2A'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select box and get all measurements\n",
    "col = mongo_db.list_collection_names()[0]\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get all sensors within a selected box**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IFU Sensebox2021 2A_Luftfeuchte 2-SHT31 Nr.2',\n",
       " 'IFU Sensebox2021 2A_Luftfeuchte 2-SHT85 Nr.0',\n",
       " 'IFU Sensebox2021 2A_Luftfeuchte 2-SHT85 Nr.1',\n",
       " 'IFU Sensebox2021 2A_Luftfeuchte 2-SHT85 Nr.2',\n",
       " 'IFU Sensebox2021 2A_Luftfeuchtigkeit 2-BME680',\n",
       " 'IFU Sensebox2021 2A_Lufttemperatur 2-BME680',\n",
       " 'IFU Sensebox2021 2A_Lufttemperatur 2-SHT31 Nr.2',\n",
       " 'IFU Sensebox2021 2A_Lufttemperatur 2-SHT85 Nr.0',\n",
       " 'IFU Sensebox2021 2A_Lufttemperatur 2-SHT85 Nr.1',\n",
       " 'IFU Sensebox2021 2A_Lufttemperatur 2-SHT85 Nr.2',\n",
       " 'IFU Sensebox2021 2A_Niederschlag',\n",
       " 'IFU Sensebox2021 2A_Sonnenstärke',\n",
       " 'IFU Sensebox2021 2A_UV',\n",
       " 'IFU Sensebox2021 2A_UVI',\n",
       " 'IFU Sensebox2021 2A_Windrichtung',\n",
       " 'IFU Sensebox2021 2A_Windstärke',\n",
       " 'IFU Sensebox2021 2A_atm. Luftdruck 2-BME680']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_names = mongo_db[col].find().distinct('_id')\n",
    "sensor_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = mongo_db[col].find_one({},{'measurments':1}) # select first sensor with field 'measurments'\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get sensor names within the Box**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IFU Sensebox2021 2A_Luftfeuchte 2-SHT31 Nr.2\n",
      "IFU Sensebox2021 2A_Luftfeuchte 2-SHT85 Nr.0\n",
      "IFU Sensebox2021 2A_Luftfeuchte 2-SHT85 Nr.1\n",
      "IFU Sensebox2021 2A_Luftfeuchte 2-SHT85 Nr.2\n",
      "IFU Sensebox2021 2A_Luftfeuchtigkeit 2-BME680\n",
      "IFU Sensebox2021 2A_Lufttemperatur 2-BME680\n",
      "IFU Sensebox2021 2A_Lufttemperatur 2-SHT31 Nr.2\n",
      "IFU Sensebox2021 2A_Lufttemperatur 2-SHT85 Nr.0\n",
      "IFU Sensebox2021 2A_Lufttemperatur 2-SHT85 Nr.1\n",
      "IFU Sensebox2021 2A_Lufttemperatur 2-SHT85 Nr.2\n",
      "IFU Sensebox2021 2A_Niederschlag\n",
      "IFU Sensebox2021 2A_Sonnenstärke\n",
      "IFU Sensebox2021 2A_UV\n",
      "IFU Sensebox2021 2A_UVI\n",
      "IFU Sensebox2021 2A_Windrichtung\n",
      "IFU Sensebox2021 2A_Windstärke\n",
      "IFU Sensebox2021 2A_atm. Luftdruck 2-BME680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = list()\n",
    "for i in sensor_names:\n",
    "    print(i)\n",
    "    results.append(mongo_db[col].find_one({'_id':i},{'measurments'}))\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 17/17 [02:37<00:00,  9.26s/it]\n"
     ]
    }
   ],
   "source": [
    "for result in tqdm(results):\n",
    "    for observation in result['measurments'].items():\n",
    "        point = Point(result['_id'].split('_')[0]) \\\n",
    "          .tag(\"sensor_name\", result['_id'].split('_')[1]) \\\n",
    "          .field(\"_value\", observation[1])\\\n",
    "          .time(datetime.strptime(observation[0], \"%Y-%m-%d %H:%M:%S\"), WritePrecision.S)\n",
    "\n",
    "        write_api.write(bucket, org, point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query InfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range(from_date,to_date,freq='4h')\n",
    "\n",
    "def to_RFC3339Date(x):\n",
    "    x = str(x)\n",
    "    x = x.replace(' ','T')\n",
    "    x = x.replace('000+00:00','Z')\n",
    "    return x\n",
    "\n",
    "times = [i for i in times][1:] # remove first time as it is equal to from_date\n",
    "times = [to_RFC3339Date(i) for i in times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████  | 41/42 [06:36<00:17, 17.36s/it]"
     ]
    }
   ],
   "source": [
    "sensor_name = \"9A\"\n",
    "box_name = \"IfU SenseBox2021 9A\"\n",
    "\n",
    "mean_runtimes = []\n",
    "std_runtimes = []\n",
    "n_init = 10\n",
    "\n",
    "for i in tqdm(range(len(times))):   \n",
    "    runtimes = [] \n",
    "    n_datepoints = []\n",
    "    \n",
    "    for _ in range(n_init):\n",
    "\n",
    "        start = time.perf_counter()\n",
    "\n",
    "        query = f'''\n",
    "            from(bucket: \"{bucket}\")\n",
    "              |> range(start: time(v: \"{from_date}\"), stop: time(v: \"{times[i]}\"))\n",
    "              |> filter(fn: (r) => r[\"_measurement\"] == \"IFU Sensebox2021 2A\")\n",
    "              |> filter(fn: (r) => r[\"_field\"] == \"_value\")\n",
    "              |> filter(fn: (r) => r[\"sensor_name\"] == \"Lufttemperatur 2-BME680\")\n",
    "              |> aggregateWindow(every: 1m, fn: mean, createEmpty: false)\n",
    "              |> yield(name: \"mean\")'''\n",
    "\n",
    "        table = client.query_api().query_data_frame(query, org=org)\n",
    "\n",
    "        end = time.perf_counter()\n",
    "\n",
    "        runtimes.append(end-start)\n",
    "        n_datepoints.append(len(table))\n",
    "    \n",
    "    mean_runtimes.append(np.mean(runtimes))\n",
    "    std_runtimes.append(np.std(runtimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0, len(mean_runtimes)), mean_runtimes)\n",
    "plt.fill_between(range(0, len(mean_runtimes)), np.subtract(mean_runtimes,std_runtimes), np.add(mean_runtimes,std_runtimes), alpha=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quellen\n",
    "\n",
    "[1]«MongoDB vs InfluxDB | InfluxData Time Series Workloads», InfluxData, Dez. 18, 2018. https://www.influxdata.com/blog/influxdb-is-27x-faster-vs-mongodb-for-time-series-workloads/ (zugegriffen Juni 17, 2021).\n",
    "\n",
    "[2]«MongoDB disk and memory requirements», Documentation & User Guides | FotoWare, Nov. 17, 2015. https://learn.fotoware.com/On-Premises/FotoWeb/05_Configuring_sites/Setting_the_MongoDB_instance_that_FotoWeb_uses/MongoDB_disk_and_memory_requirements (zugegriffen Juni 17, 2021).\n",
    "\n",
    "[3]H. 16 A. 2018 at 12:26, «InfluxDB design guidelines to avoid performance issues», Service  Engineering (ICCLab & SPLab). https://blog.zhaw.ch/icclab/influxdb-design-guidelines-to-avoid-performance-issues/ (zugegriffen Juni 17, 2021).\n",
    "\n",
    "[4]P. Dix, «InfluxDB Clustering - High Availability and Scalability», InfluxData, Sep. 10, 2020. https://www.influxdata.com/blog/influxdb-clustering/ (zugegriffen Juni 17, 2021).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
